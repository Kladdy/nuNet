{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file 1\n",
      "finished loading file 1 in 0.5706546306610107s\n",
      "loading file 2\n",
      "finished loading file 2 in 0.563478946685791s\n",
      "loading file 3\n",
      "finished loading file 3 in 0.5648424625396729s\n",
      "loading file 4\n",
      "finished loading file 4 in 0.5572545528411865s\n",
      "loading file 5\n",
      "finished loading file 5 in 0.5971784591674805s\n",
      "loading file 1\n",
      "finished loading file 1 in 0.5113587379455566s\n",
      "loading file 2\n",
      "finished loading file 2 in 0.515911340713501s\n",
      "loading file 3\n",
      "finished loading file 3 in 0.5329535007476807s\n",
      "loading file 4\n",
      "finished loading file 4 in 0.5111770629882812s\n",
      "loading file 5\n",
      "finished loading file 5 in 0.5447676181793213s\n",
      "loading file 1\n",
      "finished loading file 1 in 0.5347864627838135s\n",
      "loading file 2\n",
      "finished loading file 2 in 0.5613644123077393s\n",
      "loading file 3\n",
      "finished loading file 3 in 0.5367591381072998s\n",
      "loading file 4\n",
      "finished loading file 4 in 0.5348429679870605s\n",
      "loading file 5\n",
      "finished loading file 5 in 0.5596091747283936s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from toolbox import get_pred_energy_diff_data, common_dir, calculate_percentage_interval\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from NuRadioReco.utilities import units\n",
    "from scipy import stats\n",
    "from radiotools import stats as rtSTATS\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import product, combinations\n",
    "from radiotools import plthelpers as php\n",
    "from tensorflow import keras\n",
    "from radiotools import helper as hp\n",
    "import datasets\n",
    "# -------\n",
    "\n",
    "file_ids_to_load = [1, 2, 3, 4, 5]\n",
    "\n",
    "for dataset_to_use in [\"ALVAREZ-HAD\", \"ARZ-HAD\", \"ARZ-EM\"]:\n",
    "\n",
    "    if dataset_to_use == \"ALVAREZ-HAD\":\n",
    "        dataset_title = \"Alvarez2009 (had.)\"\n",
    "        dataset_name = \"ALVAREZ\"\n",
    "        dataset_em = False\n",
    "        dataset_noise = True\n",
    "    if dataset_to_use == \"ARZ-HAD\":\n",
    "        dataset_title = \"ARZ2020 (had.)\"\n",
    "        dataset_name = \"ARZ\"\n",
    "        dataset_em = False\n",
    "        dataset_noise = True\n",
    "    if dataset_to_use == \"ARZ-EM\":\n",
    "        dataset_title = \"ARZ2020 (had. + EM)\"\n",
    "        dataset_name = \"ARZ\"\n",
    "        dataset_em = True\n",
    "        dataset_noise = True\n",
    "\n",
    "    dataset = datasets.Dataset(dataset_name, dataset_em, dataset_noise)\n",
    "\n",
    "    # Loading data and label files\n",
    "    def load_file(i_file, norm=1e-6):\n",
    "        # Load 500 MHz filter\n",
    "        filt = np.load(f\"{common_dir()}/bandpass_filters/500MHz_filter.npy\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        print(f\"loading file {i_file}\", flush=True)\n",
    "        # data = np.load(os.path.join(dataset.datapath, f\"{dataset.data_filename}{i_file:04d}.npy\"), allow_pickle=True)\n",
    "        # data = np.fft.irfft(np.fft.rfft(data, axis=-1) * filt, axis=-1)\n",
    "        # data = data[:, :, :, np.newaxis]\n",
    "\n",
    "        labels_tmp = np.load(os.path.join(dataset.datapath, f\"{dataset.label_filename}{i_file:04d}.npy\"), allow_pickle=True)\n",
    "        print(f\"finished loading file {i_file} in {time.time() - t0}s\")\n",
    "        \n",
    "        nu_energy_data = np.array(labels_tmp.item()[\"nu_energy\"])\n",
    "\n",
    "        # # check for nans and remove them\n",
    "        # idx = ~(np.isnan(data))\n",
    "        # idx = np.all(idx, axis=1)\n",
    "        # idx = np.all(idx, axis=1)\n",
    "        # idx = np.all(idx, axis=1)\n",
    "        # data = data[idx, :, :, :]\n",
    "        # nu_energy_data = nu_energy_data[idx]\n",
    "        # data /= norm\n",
    "\n",
    "        \n",
    "\n",
    "        # return data, nu_energy_data\n",
    "        return None, nu_energy_data\n",
    "\n",
    "\n",
    "    # Load test file data\n",
    "        # Load first file\n",
    "    _, nu_energy = load_file(file_ids_to_load[0])\n",
    "\n",
    "        # Then load rest of files\n",
    "    if len(file_ids_to_load) > 1:\n",
    "        for test_file_id in file_ids_to_load:\n",
    "            if test_file_id != file_ids_to_load[0]:\n",
    "                _, nu_energy_tmp = load_file(test_file_id)\n",
    "\n",
    "                # data = np.concatenate((data, data_tmp))\n",
    "                nu_energy = np.concatenate((nu_energy, nu_energy_tmp))\n",
    "\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    nu_energy_bins = np.logspace(np.log10(1e16),np.log10(10**19), 30)\n",
    "    nu_energy_bins_with_one_extra = np.append(np.logspace(np.log10(1e16),np.log10(10**19), 30), [1e20])\n",
    "    binned_resolution_nu_energy_count = stats.binned_statistic(nu_energy, nu_energy, bins = nu_energy_bins_with_one_extra, statistic = \"count\")[0]\n",
    "    \n",
    "    ax.plot(nu_energy_bins, binned_resolution_nu_energy_count, \"*\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(r\"$\\nu$ energy (eV)\")\n",
    "    ax.set_ylabel(\"Events\")\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    plt.title(f\"Count of events inside neutrino energy bins\\nfor dataset {dataset_title}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{dataset_to_use}_counts_plot_NU_ENERGY_from1e16.png\", dpi=300)\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # ___________________________________\n",
    "\n",
    "\n",
    "    # # Calculate the weight data\n",
    "    # max_count = max(binned_resolution_nu_energy_count)\n",
    "    # weight_vector = [max_count / count_in_bin if count_in_bin != 0 else 1 for count_in_bin in binned_resolution_nu_energy_count ]\n",
    "\n",
    "    # energy_vector_log10 = np.log10(nu_energy_bins)\n",
    "    # # Plot the weights so that we can se eit\n",
    "    # plt.plot(energy_vector_log10, weight_vector)\n",
    "    # plt.xlabel(\"log10 shower energy\")\n",
    "    # plt.ylabel(\"weight\")\n",
    "    # plt.yscale(\"log\")\n",
    "    # plt.title(f\"Weight as a function of shower energy for {dataset_title}\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f\"{dataset_to_use}_weights_plot.png\", dpi=300)\n",
    "\n",
    "    # energy_weight_count_tuple = [(energy_vector_log10[i], weight_vector[i], binned_resolution_nu_energy_count[i]) for i in range(len(weight_vector))]\n",
    "\n",
    "    # with open(f\"{dataset_to_use}_weights.npy\", \"wb\") as f:  \n",
    "    #     np.save(f, energy_weight_count_tuple)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00e6b041018f9c5003ba88af84c1401696fe75920157f0e0f441a09854937f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
