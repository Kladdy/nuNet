{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 5, 512, 64)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 5, 512, 64)        20544     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 5, 512, 64)        20544     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 5, 256, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 5, 256, 128)       41088     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 256, 128)       82048     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 5, 256, 128)       82048     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 5, 128, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 263,297\n",
      "Trainable params: 263,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # GPU allocation\n",
    "# from gpuutils import GpuUtils\n",
    "# GpuUtils.allocate(gpu_count=1, framework='keras')\n",
    "\n",
    "# import tensorflow as tf\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# for device in physical_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)\n",
    "# # --------------\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "from termcolor import colored\n",
    "import time\n",
    "from toolbox import load_file, find_68_interval, models_dir\n",
    "from radiotools import helper as hp\n",
    "from PIL import Image\n",
    "\n",
    "#from scipy import stats\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv1D, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, AveragePooling1D, Input, Flatten, Conv3D\n",
    "from tensorflow.keras.layers import BatchNormalization, Lambda, MaxPooling2D, Reshape, GlobalAveragePooling3D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "from generator import TrainDataset, ValDataset, n_events_per_file, n_files_train, batch_size\n",
    "from constants import run_version, dataset_name, datapath, data_filename, label_filename, plots_dir, project_name, n_files, n_files_val, dataset_em, dataset_noise, test_file_ids\n",
    "# -------\n",
    "\n",
    "# Values\n",
    "feedback_freq = 1 # Only train on 1/feedback_freq of data per epoch\n",
    "architectures_dir = \"architectures\"\n",
    "learning_rate = 0.00005\n",
    "epochs = 100\n",
    "loss_function = \"mean_squared_error\"\n",
    "es_patience = 8\n",
    "es_min_delta = 0.0001 # Old value: es_min_delta = 0.0001\n",
    "# ------\n",
    "\n",
    "# Parse arguments\n",
    "# parser = argparse.ArgumentParser(description='Neural network for neutrino energy reconstruction')\n",
    "# parser.add_argument(\"run_id\", type=str ,help=\"the id of the run, eg '3.2' for run3.2\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "run_id = \"E30.TEST\"\n",
    "\n",
    "# Save the run name\n",
    "run_name = f\"run{run_id}\"\n",
    "\n",
    "# Make sure run_name is compatible with run_version\n",
    "this_run_version = run_name.split(\".\")[0]\n",
    "this_run_id = run_name.split(\".\")[1]\n",
    "assert this_run_version == run_version, f\"run_version ({run_version}) does not match the run version for this run ({this_run_version})\"\n",
    "\n",
    "# Models folder\n",
    "saved_model_dir = models_dir(run_name)\n",
    "\n",
    "# Make sure saved_models folder exists\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "# Make sure architectures folder exists\n",
    "if not os.path.exists(f\"{saved_model_dir}/{architectures_dir}\"):\n",
    "    os.makedirs(f\"{saved_model_dir}/{architectures_dir}\")\n",
    "\n",
    "\n",
    "# Model params\n",
    "conv2D_filter_size = 5\n",
    "pooling_size = 2\n",
    "amount_Conv2D_layers_per_block = 3 \n",
    "amount_Conv2D_blocks = 2\n",
    "conv2D_filter_amount = 64\n",
    "activation_function = \"relu\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------- Create model -----------\n",
    "model = Sequential()\n",
    "\n",
    "# Conv2D block 1\n",
    "model.add(Conv2D(conv2D_filter_amount, (1, conv2D_filter_size), strides=(1, 1), padding='same', activation=activation_function, input_shape=(5, 512, 1)))\n",
    "\n",
    "for _ in range(amount_Conv2D_layers_per_block-1):\n",
    "    model.add(Conv2D(conv2D_filter_amount, (1, conv2D_filter_size), strides=(1, 1), padding='same', activation=activation_function))\n",
    "\n",
    "# MaxPooling to reduce size\n",
    "model.add(AveragePooling2D(pool_size=(1, pooling_size)))\n",
    "\n",
    "for i in range(amount_Conv2D_blocks-1):\n",
    "    # Conv2D block\n",
    "    for _ in range(amount_Conv2D_layers_per_block):\n",
    "        model.add(Conv2D(conv2D_filter_amount*2**(i+1), (1, conv2D_filter_size), strides=(1, 1), padding='same', activation=activation_function))\n",
    "\n",
    "    # MaxPooling to reduce size\n",
    "    model.add(AveragePooling2D(pool_size=(1, pooling_size)))\n",
    "\n",
    "# model.add(Reshape((5, 128, 128, 1)))\n",
    "\n",
    "# model.add(Conv3D(32, (5, 5, 1), strides=(1, 1, 1), padding='same', activation=activation_function))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=Adam(lr=learning_rate))\n",
    "model.summary()\n",
    "# ------------------------------------\n",
    "\n",
    "# Save the model (for opening in eg Netron)\n",
    "#model.save(f'{saved_model_dir}/{architectures_dir}/model_architecture_{run_name}.h5')\n",
    "plot_model(model, to_file=f'{saved_model_dir}/{architectures_dir}/model_architecture_{run_name}.png', show_shapes=True)\n",
    "model_json = model.to_json()\n",
    "with open(f'{saved_model_dir}/{architectures_dir}/model_architecture_{run_name}.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00e6b041018f9c5003ba88af84c1401696fe75920157f0e0f441a09854937f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
